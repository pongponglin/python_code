{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因為使用scikit-learn\n",
    "#X須為2維陣列,所以需要先將list轉換為ndarray,並將其維度設為2\n",
    "#y須為1維陣列\n",
    "\n",
    "#將資料集分為訓練資料與測試資料(80/20)\n",
    "#random_state若相同，可以確保每次執行時，訓練/測試資料都是相同分割結果\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state= 31)\n",
    "    # X, y = array(num)\n",
    "    # same random_state can generate to same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "# y=係數*X+截距\n",
    "print('係數:',lr.coef_)\n",
    "print('截距',lr.intercept_)\n",
    "#regression預設使用的分數為決定係數(0~1,約接近1越好)\n",
    "print(lr.score(X_train,y_train))\n",
    "#使用X_test與y_test測試模型對未曾訓練過的資料的預測能力(泛化能力)\n",
    "print(lr.score(X_test,y_test))\n",
    "l#使用前面fit(X,y)後所學習到的函數,對X進行預測\n",
    "pred_y = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 殘差圖 residual plot\n",
    "y_pred= lr.predict(X_train)\n",
    "plt.scatter(X_train,y_pred-y_train,c='red')\n",
    "plt.hlines(0,np.min(X_train),np.max(X_train))\n",
    "plt.ylim(-100,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge/Lasso皆自動加上隨機誤差,所以不會提升訓練效果,但可能提升泛化能力.\n",
    "Width_ridge = linear_model.Ridge(alpha=1.0)              #使用Ridge regression自動進行L2正則化,多元(複)迴歸時,所有自變數的係數將變得較小\n",
    "Width_ridge.fit(X_train,y_train)            #係數變小,讓對應特徵影響最終結果的程度減少\n",
    "print(Width_ridge.score(X_train,y_train))          #因為目前範例只有一個特徵\n",
    "                                            #alpha設定regularation強度,越大越強\n",
    "\n",
    "print(\"係數:\",Width_ridge.coef_)\n",
    "print(\"截距:\",Width_ridge.intercept_)\n",
    "print(Width_ridge.score(X_test,y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Width_lasso = linear_model.Lasso(alpha=1.0)  #使用Lasso regression自動進行L1正則化,多元(複)迴歸時,有些自變數的係數將變成0\n",
    "Width_lasso.fit(X_train,y_train)             #用來減少特徵數(特徵選擇)以避免overfit(過度擬和)\n",
    "print(Width_lasso.score(X_train,y_train))            #Lasso(alpha=0)等同於OLS\n",
    "print(\"係數:\",Width_lasso.coef_)\n",
    "print(\"截距:\",Width_lasso.intercept_)\n",
    "print(Width_lasso.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#make_pipeline(step1,step2) -> data->step1->step2\n",
    "model3 = make_pipeline(PolynomialFeatures(3),linear_model.LinearRegression())\n",
    "model3.fit(X_train,y_train)\n",
    "plt.scatter(X_train,y_train,c='red')\n",
    "plt.scatter(X_test,y_test,c='green')\n",
    "plt.plot(np.sort(X_train,axis=0),model3.predict(np.sort(X_train,axis=0)))\n",
    "plt.show()\n",
    "print(\"訓練誤差\",model3.score(X_train,y_train))\n",
    "print(\"測試誤差\",model3.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DummyRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "clf_dummy = DummyRegressor(strategy='mean')   #任何輸入都回傳train_y的平均值\n",
    "clf_dummy.fit(X_train,y_train)\n",
    "clf_dummy.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = LogisticRegression(penalty=None) \n",
    "model_p.fit(X,y)\n",
    "model_p.score(X,y) \n",
    "\n",
    "#降低C值,希望能夠避免overfit\n",
    "model = LogisticRegression(C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PolynomialFeatures 線性不可分時\n",
    "from sklearn import preprocessing\n",
    "poly5 = preprocessing.PolynomialFeatures(5) # 1, x1, x2, x1^2, x1*x2, x2, x1^3, .... x1*x2^4, x2^5 \n",
    "X = poly5.fit_transform(np.c_[data['x1'],data['x2']]) # np.c_[array1,array2]按照column連接兩個array,np.r_[]則按照row連接\n",
    "LR_poly5 = linear_model.LogisticRegression(penalty='l2', C=1.0) #l2是預設值,採用Ridge(降低特徵係數值)\n",
    "LR_poly5.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
